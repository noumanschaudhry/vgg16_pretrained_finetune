{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "nb_train_samples = 3000 # 3000 training samples\n",
    "nb_valid_samples = 100 # 100 validation samples\n",
    "num_classes = 10\n",
    "\n",
    "def load_cifar10_data(img_rows, img_cols):\n",
    "\n",
    "    # Load cifar10 training and validation sets\n",
    "    (X_train, Y_train), (X_valid, Y_valid) = cifar10.load_data()\n",
    "\n",
    "    # Resize trainging images\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        X_train = np.array([cv2.resize(img.transpose(1,2,0), (img_rows,img_cols)).transpose(2,0,1) for img in X_train[:nb_train_samples,:,:,:]])\n",
    "        X_valid = np.array([cv2.resize(img.transpose(1,2,0), (img_rows,img_cols)).transpose(2,0,1) for img in X_valid[:nb_valid_samples,:,:,:]])\n",
    "    else:\n",
    "        X_train = np.array([cv2.resize(img, (img_rows,img_cols)) for img in X_train[:nb_train_samples,:,:,:]])\n",
    "        X_valid = np.array([cv2.resize(img, (img_rows,img_cols)) for img in X_valid[:nb_valid_samples,:,:,:]])\n",
    "\n",
    "    # Transform targets to keras compatible format\n",
    "    Y_train = np_utils.to_categorical(Y_train[:nb_train_samples], num_classes)\n",
    "    Y_valid = np_utils.to_categorical(Y_valid[:nb_valid_samples], num_classes)\n",
    "\n",
    "    return X_train, Y_train, X_valid, Y_valid\n",
    "\n",
    "def vgg16_model(img_rows, img_cols, channel=1, num_classes=None):\n",
    "    \"\"\"VGG 16 Model for Keras\n",
    "    Model Schema is based on \n",
    "    https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3\n",
    "    ImageNet Pretrained Weights \n",
    "    https://drive.google.com/file/d/0Bz7KyqmuGsilT0J5dmRCM0ROVHc/view?usp=sharing\n",
    "    Parameters:\n",
    "      img_rows, img_cols - resolution of inputs\n",
    "      channel - 1 for grayscale, 3 for color \n",
    "      num_classes - number of categories for our classification task\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1, 1), input_shape=(channel, img_rows, img_cols)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Add Fully Connected Layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "\n",
    "    # Loads ImageNet pre-trained data\n",
    "    model.load_weights('imagenet_models/vgg16_weights.h5')\n",
    "\n",
    "    # Truncate and replace softmax layer for transfer learning\n",
    "    model.layers.pop()\n",
    "    model.outputs = [model.layers[-1].output]\n",
    "    model.layers[-1].outbound_nodes = []\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # Uncomment below to set the first 10 layers to non-trainable (weights will not be updated)\n",
    "    #for layer in model.layers[:10]:\n",
    "    #    layer.trainable = False\n",
    "\n",
    "    # Learning rate is changed to 0.001\n",
    "    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Example to fine-tune on 3000 samples from Cifar10\n",
    "\n",
    "    img_rows, img_cols = 224, 224 # Resolution of inputs\n",
    "    channel = 3\n",
    "    num_classes = 10 \n",
    "    batch_size = 16 \n",
    "    nb_epoch = 10\n",
    "\n",
    "    # Load Cifar10 data. Please implement your own load_data() module for your own dataset\n",
    "    X_train, Y_train, X_valid, Y_valid = load_cifar10_data(img_rows, img_cols)\n",
    "\n",
    "    # Load our model\n",
    "    model = vgg16_model(img_rows, img_cols, channel, num_classes)\n",
    "\n",
    "    # Start Fine-tuning\n",
    "    model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size,\n",
    "              nb_epoch=nb_epoch,\n",
    "              shuffle=True,\n",
    "              verbose=1,\n",
    "              validation_data=(X_valid, Y_valid),\n",
    "              )\n",
    "\n",
    "    # Make predictions\n",
    "    predictions_valid = model.predict(X_valid, batch_size=batch_size, verbose=1)\n",
    "\n",
    "    # Cross-entropy loss score\n",
    "    score = log_loss(Y_valid, predictions_valid)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
